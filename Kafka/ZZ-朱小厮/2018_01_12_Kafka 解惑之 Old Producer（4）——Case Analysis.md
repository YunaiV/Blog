title: Kafka è§£æƒ‘ä¹‹ Old Producerï¼ˆ4ï¼‰â€”â€”Case Analysis
date: 2018-01-12
tag: 
categories: Kafka
permalink: Kafka/old-producer-case-analysis
author: æœ±å°å®
from_url: https://blog.csdn.net/u013256816/article/details/79237769
wechat_url: 

-------

æ‘˜è¦: åŸåˆ›å‡ºå¤„ https://blog.csdn.net/u013256816/article/details/79237769 ã€Œæœ±å°å®ã€æ¬¢è¿è½¬è½½ï¼Œä¿ç•™æ‘˜è¦ï¼Œè°¢è°¢ï¼

-------

![](http://www.iocoder.cn/images/common/wechat_mp_2017_07_31.jpg)

> ğŸ™‚ğŸ™‚ğŸ™‚å…³æ³¨**å¾®ä¿¡å…¬ä¼—å·ï¼šã€èŠ‹é“æºç ã€‘**æœ‰ç¦åˆ©ï¼š
> 1. RocketMQ / MyCAT / Sharding-JDBC **æ‰€æœ‰**æºç åˆ†ææ–‡ç« åˆ—è¡¨
> 2. RocketMQ / MyCAT / Sharding-JDBC **ä¸­æ–‡æ³¨é‡Šæºç  GitHub åœ°å€**
> 3. æ‚¨å¯¹äºæºç çš„ç–‘é—®æ¯æ¡ç•™è¨€**éƒ½**å°†å¾—åˆ°**è®¤çœŸ**å›å¤ã€‚**ç”šè‡³ä¸çŸ¥é“å¦‚ä½•è¯»æºç ä¹Ÿå¯ä»¥è¯·æ•™å™¢**ã€‚
> 4. **æ–°çš„**æºç è§£ææ–‡ç« **å®æ—¶**æ”¶åˆ°é€šçŸ¥ã€‚**æ¯å‘¨æ›´æ–°ä¸€ç¯‡å·¦å³**ã€‚
> 5. **è®¤çœŸçš„**æºç äº¤æµå¾®ä¿¡ç¾¤ã€‚

-------

åœ¨å‰é¢ä¸‰ç¯‡æ–‡ç« ä¸­è¯¦ç»†äº†è§£äº†Old Producerçš„å†…å®¹ï¼Œæœ¬æ–‡ä¸»è¦é€šè¿‡ä¸€ä¸ªå®é™…åº”ç”¨æ¡ˆä¾‹æ¥åŠ æ·±å„ä½å¯¹Old Producerçš„ç†è§£ã€‚

é—®é¢˜æè¿°ï¼šçº¿ä¸Šç”±å¤šå°Kafka Brokerç»„æˆçš„é›†ç¾¤ï¼ˆProducerçš„metadata.broker.listå‚æ•°è®¾ç½®çš„æ˜¯æ‰€æœ‰brokerçš„åœ°å€+ç«¯å£å·çš„åˆ—è¡¨ï¼‰ï¼Œç‰ˆæœ¬å·ä¸º0.8.2.xï¼Œå½“ä¸€å°Kafka Brokerçš„ç¡¬ç›˜å‘ç”Ÿæ•…éšœå¯¼è‡´ç³»ç»Ÿå´©æºƒï¼Œç”±äºKafkaçš„HAçš„ä½œç”¨çº¿ä¸Šä¸šåŠ¡æ— æ˜æ˜¾å¼‚å¸¸ï¼Œå‘é€æ–¹å’Œæ¶ˆè´¹æ–¹çš„æµé‡ä¹Ÿä¸ä¹‹å‰æŒç¨³ï¼Œä½†æ˜¯åé¢ç›‘æµ‹åˆ°æ¯éš”10åˆ†é’Ÿå·¦å³å°±æœ‰å°‘é‡çš„æ¶ˆæ¯å‘é€çš„æ—¶å»¶å¾ˆå¤§ï¼Œè€Œä¸”æœ‰ERRORå‘Šè­¦æŠ¥å‡ºã€‚

```java
2018-01-30 00:53:20 -[ERROR] - [fetching topic metadata for topics [Set(hidden-topic)] from broker [ArrayBuffer(id:0,host:xxx.xxx.xxx.xxx,port:9092)] failed] - [kafka.utils.Logging$$anonfun$swallowError$1:106]
kafka.common.KafkaException: fetching topic metadata for topics [Set(hidden-topic)] from broker [ArrayBuffer(id:0,host:xxx.xxx.xxx.xxx,port:9092)] failed
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:72)
	at kafka.producer.BrokerPartitionInfo.updateInfo(BrokerPartitionInfo.scala:82)
	at kafka.producer.async.DefaultEventHandler$$anonfun$handle$1.apply$mcV$sp(DefaultEventHandler.scala:67)
    at kafka.utils.Utils$.swallow(Utils.scala:172)
    at kafka.utils.Logging$class.swallowError(Logging.scala:106)
    at kafka.utils.Utils$.swallowError(Utils.scala:45)
    at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:67)
    at kafka.producer.Producer.send(Producer.scala:77)
    at kafka.javaapi.producer.Producer.send(Producer.scala:33)
```

é€šè¿‡ä¸Šé¢çš„å¼‚å¸¸æ ˆæˆ‘ä»¬å¯ä»¥å‘ç°åœ¨è·å–å…ƒæ•°æ®çš„æ—¶å€™ï¼ˆkafka.client.ClientUtils$.fetchTopicMetadataï¼‰å‘ç”Ÿäº†å¼‚å¸¸ï¼Œå…¶å®å¦‚æœä½ å¯¹Kafkaçš„é…ç½®å‚æ•°è¶³å¤Ÿäº†è§£çš„è¯ï¼Œçœ‹åˆ°10åˆ†é’Ÿè¿™ä¸ªæ•°å€¼å°±å¯ä»¥è”æƒ³åˆ°600*1000çš„æŸä¸ªå‚æ•°ï¼Œä¹Ÿå°±æ˜¯topic.metadata.refresh.interval.msã€‚åœ¨DefaultEventHandlerçš„handle()æ–¹æ³•ä¸­ï¼Œåœ¨è°ƒç”¨dispatchSerializedData()æ–¹æ³•é¢„å¤„ç†å¹¶å‘é€æ¶ˆæ¯ä¹‹å‰å°±ä¼šæœ‰ä¸‹é¢çš„ä¸€ä¸ªifåˆ¤æ–­è¯­è¨€ç”¨æ¥åˆ¤æ–­å½“å‰æ˜¯å¦éœ€è¦æ›´æ–°å…ƒæ•°æ®ï¼š

```java
while (remainingRetries > 0 && outstandingProduceRequests.nonEmpty) {
  topicMetadataToRefresh ++= outstandingProduceRequests.map(_.topic)
  if (topicMetadataRefreshInterval >= 0 &&
      Time.SYSTEM.milliseconds - lastTopicMetadataRefreshTime > topicMetadataRefreshInterval) {
    CoreUtils.swallowError(brokerPartitionInfo.updateInfo(topicMetadataToRefresh.toSet, correlationId.getAndIncrement))
    sendPartitionPerTopicCache.clear()
    topicMetadataToRefresh.clear
    lastTopicMetadataRefreshTime = Time.SYSTEM.milliseconds
  }
  outstandingProduceRequests = dispatchSerializedData(outstandingProduceRequests)
```

ä¸Šé¢ä»£ç ä¸­çš„topicMetadataRefreshIntervalæŒ‡çš„å°±æ˜¯topic.metadata.refresh.interval.mså‚æ•°ã€‚å¦‚æœtopic.metadata.refresh.interval.msè¿™ä¸ªå‚æ•°è®¾ç½®ä¸º0ï¼Œé‚£ä¹ˆå°±æ„å‘³ç€æ¯æ¬¡å‘é€æ¶ˆæ¯ä¹‹å‰éƒ½éœ€è¦æ‹‰å–å¹¶æ›´æ–°å…ƒæ•°æ®ä¿¡æ¯ï¼Œæ›´æ–°å…ƒæ•°æ®ä¿¡æ¯ä¹‹åè¿˜è¦æ›´æ–°ProducerPoolçš„å†…å®¹ï¼ŒåŒ…æ‹¬é‡å»ºSyncProducerï¼Œé‚£ä¹ˆè¿™ä¸€ç•ªæ“ä½œå¿…ç„¶ä¼šæœ‰ä¸€å®šçš„å»¶è¿Ÿï¼Œå½“ç„¶è¿™ä¸ªå»¶è¿Ÿæ²¡æœ‰æœ¬æ–‡ä¸­æ‰€è¿°é—®é¢˜ä¸­çš„å»¶è¿Ÿé‚£ä¹ˆå¤§ã€‚å¦‚æœtopic.metadata.refresh.interval.msè¿™ä¸ªå‚æ•°è®¾ç½®ä¸ºè´Ÿæ•°ï¼Œé‚£ä¹ˆè¿™ä¸ªifæ¡ä»¶è¯­å¥å°±ä¸èƒ½æˆç«‹ï¼Œä¹Ÿå°±æ˜¯ä¸ä¼šæœ‰å®šæ—¶æ›´æ–°å…ƒæ•°æ®çš„æ“ä½œï¼Œåªæœ‰åœ¨è·å–å…ƒæ•°æ®ä¿¡æ¯å¤±è´¥æ˜¯æ‰ä¼šè¯·æ±‚å®Œæ•´çš„å…ƒæ•°æ®ä¿¡æ¯ã€‚

æœ¬æ–‡ä¸­æ‰€è¿°é—®é¢˜ä¸­é‡‡ç”¨çš„topic.metadata.refresh.interval.mså‚æ•°è®¾ç½®çš„æ˜¯é»˜è®¤å€¼å¤§å°ï¼Œé‚£ä¹ˆé—®é¢˜ä¸­è¿˜æœ‰ä¸€ä¸ªç»†èŠ‚ï¼šåªæœ‰å°‘é‡æ¶ˆæ¯å‘é€è¶…æ—¶ã€‚ä¸ºäº†è¿›ä¸€æ­¥çš„ä¸€æ¢ç©¶ç«Ÿï¼Œæˆ‘ä»¬æ¥ç»§ç»­æ·±ç©¶ã€‚å½“å®šæ—¶æ›´æ–°å…ƒæ•°æ®ä¿¡æ¯æ¡ä»¶æ»¡è¶³æ—¶ï¼Œå°±ä¼šè°ƒç”¨brokerPartitionInfo.updateInfoçš„æ–¹æ³•ï¼Œæ›´è¿›å–ä¹‹åï¼Œå®é™…ä¸Šå†…éƒ¨è°ƒç”¨çš„æ˜¯ï¼šClientUtils.fetchTopicMetadata(topics, brokers, producerConfig, correlationId)æ¥è¯·æ±‚å…ƒæ•°æ®ä¿¡æ¯ï¼Œå¹¶è·å¾—TopicMetadataResponseæ¥åšæ›´æ–°ã€‚

TopicMetadataResponseä¸­åŒ…å«æœ‰brokerçš„idã€hostã€portï¼Œè¿˜æœ‰topicã€topicä¸­çš„partitionã€partitionæ‰€å¯¹åº”çš„leaderã€ARå’ŒISRç­‰ç­‰ï¼Œæœ‰å…´è¶£çš„åŒå­¦å¯ä»¥è¿›ä¸€æ­¥ç¿»é˜…kafka.api.TopicMetadataResponseè¿™ä¸ªç±»ï¼Œä¸»ä½“ä»£ç åªæœ‰30è¡Œå·¦å³ï¼Œåªè¦å­¦ä¸€ç‚¹Scalaçš„æ„é€ å‡½æ•°ç›¸å…³çš„åªæ˜¯å°±èƒ½çœ‹æ‡‚ã€‚

æˆ‘ä»¬å›è¿‡å¤´æ¥å†æ¥è¿›ä¸€æ­¥åˆ†æClientUtils.fetchTopicMetadataè¿™ä¸ªæ–¹æ³•ï¼Œè¯¦ç»†ä»£ç å¦‚ä¸‹ï¼š

```java
def fetchTopicMetadata(topics: Set[String], brokers: Seq[BrokerEndPoint], producerConfig: ProducerConfig, correlationId: Int): TopicMetadataResponse = {
  var fetchMetaDataSucceeded: Boolean = false
  var i: Int = 0
  val topicMetadataRequest = new TopicMetadataRequest(TopicMetadataRequest.CurrentVersion, correlationId, producerConfig.clientId, topics.toSeq)
  var topicMetadataResponse: TopicMetadataResponse = null
  var t: Throwable = null
  // shuffle the list of brokers before sending metadata requests so that most requests don't get routed to the
  // same broker
  val shuffledBrokers = Random.shuffle(brokers)
  while(i < shuffledBrokers.size && !fetchMetaDataSucceeded) {
    val producer: SyncProducer = ProducerPool.createSyncProducer(producerConfig, shuffledBrokers(i))
    info("Fetching metadata from broker %s with correlation id %d for %d topic(s) %s".format(shuffledBrokers(i), correlationId, topics.size, topics))
    try {
      topicMetadataResponse = producer.send(topicMetadataRequest)
      fetchMetaDataSucceeded = true
    }
    catch {
      case e: Throwable =>
        warn("Fetching topic metadata with correlation id %d for topics [%s] from broker [%s] failed"
          .format(correlationId, topics, shuffledBrokers(i).toString), e)
        t = e
    } finally {
      i = i + 1
      producer.close()
    }
  }
  if(!fetchMetaDataSucceeded) {
    throw new KafkaException("fetching topic metadata for topics [%s] from broker [%s] failed".format(topics, shuffledBrokers), t)
  } else {
    debug("Successfully fetched metadata for %d topic(s) %s".format(topics.size, topics))
  }
  topicMetadataResponse
}
```

fetchTopicMetadataæ–¹æ³•å‚æ•°åˆ—è¡¨ä¸­brokersä»£è¡¨metadata.broker.listæ‰€é…ç½®çš„åœ°å€åˆ—è¡¨ã€‚å¯ä»¥çœ‹åˆ°æ–¹æ³•ä¸­é¦–å…ˆå»ºç«‹TopicMetadataRequestçš„è¯·æ±‚ï¼Œç„¶åä»brokersä¸­éšæœºæŒ‘é€‰ï¼ˆåšä¸€ä¸ªshuffleï¼Œç„¶åä»åˆ—è¡¨ä¸­çš„ç¬¬ä¸€ä¸ªå¼€å§‹å–ï¼Œä¹Ÿå°±æ˜¯ç›¸å½“äºéšæœºï¼‰ä¸€ä¸ªbrokerå»ºç«‹SyncProducerå¹¶å‘é€TopicMetadataRequestè¯·æ±‚ï¼Œé—®é¢˜çš„å…³é”®å°±åœ¨è¿™ä¸ªéšæœºæŒ‘é€‰ä¸€ä¸ªbrokerä¹‹ä¸Šï¼Œå¦‚æœæ­£å¥½éšæœºåˆ°çš„æ˜¯é‚£å°ç£ç›˜æŸæ¯è€Œå´©æºƒçš„æœºå™¨ï¼Œé‚£ä¹ˆè¿™ä¸ªè¯·æ±‚å¿…å®šè¦ç­‰åˆ°è®¾å®šçš„è¶…æ—¶æ—¶é—´ä¹‹åæ‰èƒ½æ•è·å¼‚å¸¸ï¼š[ERROR] - [fetching topic metadata for topics [Set(hidden-topic)] from broker [ArrayBuffer(id:0,host:xxx.xxx.xxx.xxx,port:9092)] failed] ï¼Œè¿›è€Œå†æ‰¾åˆ°ä¸‹ä¸€ä¸ªbrokeré‡æ–°å‘é€TopicMetadataRequestè¯·æ±‚ã€‚

ä¸Šé¢æåˆ°äº†è¶…æ—¶æ—¶é—´ï¼Œè¿™ä¸ªè¶…æ—¶æ—¶é—´æ˜¯é€šè¿‡request.timeout.mså‚æ•°è®¾å®šçš„ï¼Œé»˜è®¤å€¼ä¸º10000ï¼Œä¹Ÿå°±æ˜¯10sã€‚å…·ä½“æŒ‡çš„æ˜¯kafka.network.BlockingChannelä¸­çš„channel.socket.connect(new InetSocketAddress(host, port), connectTimeoutMs)è¿™æ®µä»£ç ï¼Œå‚æ•°connectTimeoutMså°±æ˜¯æŒ‡request.timeout.msã€‚å¦‚æœå…ƒæ•°æ®çš„è¯·æ±‚æ—¶æ‰“åˆ°é‚£å°å´©æºƒçš„brokerä¸Šçš„è¯ï¼Œé‚£ä¹ˆå…ƒæ•°æ®çš„è¯·æ±‚å°±è¦è€—æ—¶10sä»¥ä¸Šï¼Œå¾…å…ƒæ•°æ®åˆ·æ–°åæ‰èƒ½å‘é€æ¶ˆæ¯ã€‚è¿™ä¸ªrequest.timeout.mså‚æ•°æ‰æ˜¯å¯¼è‡´æ–‡ä¸­å¼€å¤´æœ‰å°‘é‡æ¶ˆæ¯å‘é€æ—¶å»¶å¾ˆå¤§çš„åŸå› ã€‚ä¸ºäº†è¿›ä¸€æ­¥éªŒè¯ç»“è®ºæ˜¯å¦æ­£ç¡®ï¼Œç¬”è€…å°†ç›¸å…³çš„ç±»SyncProducerã€BlockingChannelç”¨Javaé‡å†™äº†ä¸€éï¼Œå¹¶æµ‹è¯•å‡ºè¯·æ±‚çš„è€—æ—¶ï¼Œå½“è®¿é—®ä¸€ä¸ªä¸å­˜åœ¨çš„ipåœ°å€æ—¶ï¼Œä»å‘é€è¯·æ±‚åˆ°å¼‚å¸¸æŠ¥å‡ºçš„è€—æ—¶åœ¨10194msã€‚ä¸è¿‡å¦‚æœè®¿é—®ä¸€ä¸ªå­˜åœ¨çš„ipåœ°å€æ—¶ï¼Œä½†æ˜¯æ²¡æœ‰kafkaæœåŠ¡çš„è¯ï¼Œä»å‘é€è¯·æ±‚åˆ°è¿”å›çš„è€—æ—¶åªæœ‰1248msï¼ŒåŸºæœ¬ä¸Šå‡å°‘äº†ä¸€ä¸ªæ•°é‡çº§ï¼Œå¦‚æœè¯»è€…åœ¨é‡åˆ°åŒæ ·çš„é—®é¢˜æ—¶ï¼Œä¸å¦¨ä¸Šçº¿ä¸€å°ï¼ˆéšæ„ä¸€å°èƒ½å»ºç«‹TCPè¿æ¥çš„æœºå™¨å°±å¥½ï¼‰ä¸å´©æºƒå®•æœºçš„é‚£å°brokerä¸€æ ·çš„ipåœ°å€çš„æœºå™¨ï¼Œä¸Šé¢æ— éœ€è¿è¡Œkafkaçš„æœåŠ¡ï¼Œå°±èƒ½å¤§å¤§çš„é™ä½å‘é€æ¶ˆæ¯çš„æ—¶å»¶ã€‚è¿™æ ·å¯ä»¥æµå‡ºæ›´å¤šçš„æ—¶é—´å»å®šä½ã€ä¿®å¤ã€é‡æ–°ä¸Šçº¿é‚£å°å´©æºƒçš„brokerã€‚

å½“ç„¶å¦‚æœå¯¹æ—¶å»¶è¿‡æ•ï¼Œè¿˜æœ‰ä¸€äº›å…¶å®ƒçš„æ–¹æ³•å¯ä»¥å‚è€ƒã€‚æ¯”å¦‚metadata.broker.listé…ç½®çš„æ˜¯ä¸€ä¸ªç±»ä¼¼è™šIPï¼ˆVIPï¼‰çš„è¯ï¼Œå¯ä»¥åœ¨VIPçš„ä¸‹æ¸¸å‰”é™¤æ‰è¿™å°brokerï¼Œè®©VIPè¿‡æ¥çš„è¯·æ±‚ä¸ä¼šè½åˆ°å´©æºƒçš„brokerä¸Šã€‚æˆ–è€…ä¹Ÿå¯ä»¥é€šè¿‡topic.metadata.refresh.interval.mså‚æ•°æ¥è°ƒèŠ‚ï¼Œæ¯”å¦‚è®¾ç½®ä¸ºè´Ÿæ•°å°±å¯ä»¥å…å»å®šæ—¶åˆ·æ–°å…ƒæ•°æ®çš„çƒ¦æ¼ï¼Œä¸è¿‡åœ¨å…ƒæ•°æ®å˜åŠ¨çš„æ—¶å€™å¾ˆéš¾æœ‰æ•ˆçš„æ„ŸçŸ¥å…¶å˜åŒ–ï¼Œé€šè¿‡å®šæ—¶é‡è¿ä¹‹ç±»çš„æ–¹æ³•åˆæ˜¾å¾—æœ‰ç‚¹å¥‡è‘©ã€‚å½“ç„¶ç›´æ¥ä¸Šçº¿ä¸€å°æœåŠ¡å™¨ï¼Œå®‰è£…è¿è¡ŒkafkaæœåŠ¡ï¼Œä¸”è®¾ç½®è¿™å°kafkaæœåŠ¡å™¨çš„ipä¸ºå´©æºƒçš„é‚£å°æœåŠ¡å™¨çš„ipåœ°å€ï¼Œä¸è¿‡è¿™ç•ªæ“ä½œæ¯”ç›´æ¥æ‹‰ä¸€å°ç©ºæœºå™¨çš„æ—¶æ•ˆæ€§è¦ä½ä¸€äº›ï¼Œå‡¡äº‹åœ¨äºæŠ‰æ‹©ã€‚

Old Produceræ‹‰å–å…ƒæ•°æ®ä¿¡æ¯ä»¥åŠå‘é€æ¶ˆæ¯æ˜¯åœ¨åŒä¸€ä¸ªçº¿ç¨‹ä¸­çš„ï¼Œè¿™å¿…ç„¶ä¼šå¼•èµ·å±€éƒ¨æ¶ˆæ¯çš„æ—¶å»¶å¢å¤§ã€‚ä¸è¿‡åœ¨æ–°ç‰ˆçš„KafkaProducerä¸­ï¼Œè¿™äº›é—®é¢˜éƒ½å·²ç»è¿åˆƒè€Œè§£ï¼Œå…·ä½“æ€ä¹ˆå¤„ç†ï¼Œä¸”çœ‹åé¢çš„æ–‡ç« åˆ†æã€‚

# 666. å½©è›‹

å¦‚æœä½ å¯¹ Kafka å¹¶å‘æ„Ÿå…´è¶£ï¼Œæ¬¢è¿åŠ å…¥æˆ‘çš„çŸ¥è¯†ä¸€èµ·äº¤æµã€‚

![çŸ¥è¯†æ˜Ÿçƒ](http://www.iocoder.cn/images/Architecture/2017_12_29/01.png)