title: Kafka æ¶ˆæ¯åºåˆ—åŒ–å’Œååºåˆ—åŒ–ï¼ˆä¸‹ï¼‰
date: 2018-01-05
tag: 
categories: Kafka
permalink: Kafka/message-serialize-1
author: æœ±å°å®
from_url: https://blog.csdn.net/u013256816/article/details/78657995
wechat_url: 

-------

æ‘˜è¦: åŸåˆ›å‡ºå¤„ https://blog.csdn.net/u013256816/article/details/78657995 ã€Œæœ±å°å®ã€æ¬¢è¿è½¬è½½ï¼Œä¿ç•™æ‘˜è¦ï¼Œè°¢è°¢ï¼

-------

![](http://www.iocoder.cn/images/common/wechat_mp_2017_07_31.jpg)

> ğŸ™‚ğŸ™‚ğŸ™‚å…³æ³¨**å¾®ä¿¡å…¬ä¼—å·ï¼šã€èŠ‹é“æºç ã€‘**æœ‰ç¦åˆ©ï¼š
> 1. RocketMQ / MyCAT / Sharding-JDBC **æ‰€æœ‰**æºç åˆ†ææ–‡ç« åˆ—è¡¨
> 2. RocketMQ / MyCAT / Sharding-JDBC **ä¸­æ–‡æ³¨é‡Šæºç  GitHub åœ°å€**
> 3. æ‚¨å¯¹äºæºç çš„ç–‘é—®æ¯æ¡ç•™è¨€**éƒ½**å°†å¾—åˆ°**è®¤çœŸ**å›å¤ã€‚**ç”šè‡³ä¸çŸ¥é“å¦‚ä½•è¯»æºç ä¹Ÿå¯ä»¥è¯·æ•™å™¢**ã€‚
> 4. **æ–°çš„**æºç è§£ææ–‡ç« **å®æ—¶**æ”¶åˆ°é€šçŸ¥ã€‚**æ¯å‘¨æ›´æ–°ä¸€ç¯‡å·¦å³**ã€‚
> 5. **è®¤çœŸçš„**æºç äº¤æµå¾®ä¿¡ç¾¤ã€‚

-------

æœ‰åºåˆ—åŒ–å°±ä¼šæœ‰ååºåˆ—åŒ–ï¼Œååºåˆ—åŒ–çš„æ“ä½œæ˜¯åœ¨Kafka Consumerä¸­å®Œæˆçš„ï¼Œä½¿ç”¨èµ·æ¥åªéœ€è¦é…ç½®ä¸€ä¸‹key.deserializerå’Œvalue.deseriaizerã€‚å¯¹åº”ä¸Šé¢è‡ªå®šä¹‰çš„Companyç±»å‹çš„Deserializerå°±éœ€è¦å®ç°org.apache.kafka.common.serialization.Deserializeræ¥å£ï¼Œè¿™ä¸ªæ¥å£åŒæ ·æœ‰ä¸‰ä¸ªæ–¹æ³•ï¼š

1. public void configure(Map<String, ?> configs, boolean isKey)ï¼šç”¨æ¥é…ç½®å½“å‰ç±»ã€‚
2. public byte[] serialize(String topic, T data)ï¼šç”¨æ¥æ‰§è¡Œååºåˆ—åŒ–ã€‚å¦‚æœdataä¸ºnullå»ºè®®å¤„ç†çš„æ—¶å€™ç›´æ¥è¿”å›nullè€Œä¸æ˜¯æŠ›å‡ºä¸€ä¸ªå¼‚å¸¸ã€‚
3. public void close()ï¼šç”¨æ¥å…³é—­å½“å‰åºåˆ—åŒ–å™¨ã€‚

ä¸‹é¢å°±æ¥çœ‹ä¸€ä¸‹DemoSerializerå¯¹åº”çš„ååºåˆ—åŒ–çš„DemoDeserializerï¼Œè¯¦ç»†ä»£ç å¦‚ä¸‹ï¼š

```Java
public class DemoDeserializer implements Deserializer<Company> {
    public void configure(Map<String, ?> configs, boolean isKey) {}
    public Company deserialize(String topic, byte[] data) {
        if (data == null) {
            return null;
        }
        if (data.length < 8) {
            throw new SerializationException("Size of data received by DemoDeserializer is shorter than expected!");
        }
        ByteBuffer buffer = ByteBuffer.wrap(data);
        int nameLen, addressLen;
        String name, address;
        nameLen = buffer.getInt();
        byte[] nameBytes = new byte[nameLen];
        buffer.get(nameBytes);
        addressLen = buffer.getInt();
        byte[] addressBytes = new byte[addressLen];
        buffer.get(addressLen);
        try {
            name = new String(nameBytes, "UTF-8");
            address = new String(addressBytes, "UTF-8");
        } catch (UnsupportedEncodingException e) {
            throw new SerializationException("Error occur when deserializing!");
        }
        return new Company(name,address);
    }
    public void close() {}
}
```

æœ‰äº›è¯»è€…å¯èƒ½å¯¹æ–°ç‰ˆçš„Consumerä¸æ˜¯å¾ˆç†Ÿæ‚‰ï¼Œè¿™é‡Œé¡ºå¸¦ç€ä¸¾ä¸€ä¸ªå®Œæ•´çš„æ¶ˆè´¹ç¤ºä¾‹ï¼Œå¹¶ä»¥DemoDeserializerä½œä¸ºæ¶ˆæ¯Valueçš„ååºåˆ—åŒ–å™¨ã€‚

```Java
Properties properties = new Properties();
properties.put("bootstrap.servers", brokerList);
properties.put("group.id", consumerGroup);
properties.put("session.timeout.ms", 10000);
properties.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
properties.put("value.deserializer", "com.hidden.client.DemoDeserializer");
properties.put("client.id", "hidden-consumer-client-id-zzh-2");
KafkaConsumer<String, Company> consumer = new KafkaConsumer<String, Company>(properties);
consumer.subscribe(Arrays.asList(topic));
try {
    while (true) {
        ConsumerRecords<String, Company> records = consumer.poll(100);
        for (ConsumerRecord<String, Company> record : records) {
            String info = String.format("topic=%s, partition=%s, offset=%d, consumer=%s, country=%s",
                    record.topic(), record.partition(), record.offset(), record.key(), record.value());
            System.out.println(info);
        }
        consumer.commitAsync(new OffsetCommitCallback() {
            public void onComplete(Map<TopicPartition, OffsetAndMetadata> offsets, Exception exception) {
                if (exception != null) {
                    String error = String.format("Commit failed for offsets {}", offsets, exception);
                    System.out.println(error);
                }
            }
        });
    }
} finally {
    consumer.close();
}
```

æœ‰äº›æ—¶å€™è‡ªå®šä¹‰çš„ç±»å‹è¿˜å¯ä»¥å’ŒAvroã€ProtoBufç­‰è”åˆä½¿ç”¨ï¼Œè€Œä¸”è¿™æ ·æ›´åŠ çš„æ–¹ä¾¿å¿«æ·ï¼Œæ¯”å¦‚æˆ‘ä»¬å°†å‰é¢Companyçš„Serializerå’ŒDeserializerç”¨ProtostuffåŒ…è£…ä¸€ä¸‹ï¼Œç”±äºç¯‡å¹…é™åˆ¶ï¼Œç¬”è€…è¿™é‡Œåªç½—åˆ—å‡ºå¯¹åº”çš„serializeå’Œdeserializeæ–¹æ³•ï¼Œè¯¦ç»†å‚è€ƒå¦‚ä¸‹ï¼š

```Java
public byte[] serialize(String topic, Company data) {
    if (data == null) {
        return null;
    }
    Schema schema = (Schema) RuntimeSchema.getSchema(data.getClass());
    LinkedBuffer buffer = LinkedBuffer.allocate(LinkedBuffer.DEFAULT_BUFFER_SIZE);
    byte[] protostuff = null;
    try {
        protostuff = ProtostuffIOUtil.toByteArray(data, schema, buffer);
    } catch (Exception e) {
        throw new IllegalStateException(e.getMessage(), e);
    } finally {
        buffer.clear();
    }
    return protostuff;
}

public Company deserialize(String topic, byte[] data) {
    if (data == null) {
        return null;
    }
    Schema schema = RuntimeSchema.getSchema(Company.class);
    Company ans = new Company();
    ProtostuffIOUtil.mergeFrom(data, ans, schema);
    return ans;
}
```

å¦‚æœCompanyçš„å­—æ®µå¾ˆå¤šï¼Œæˆ‘ä»¬ä½¿ç”¨Protostuffè¿›ä¸€æ­¥å°è£…ä¸€ä¸‹çš„æ–¹å¼å°±æ˜¾å¾—ç®€æ´å¾ˆå¤šã€‚ä¸è¿‡è¿™ä¸ªä¸æ˜¯æœ€ä¸»è¦çš„ï¼Œè€Œæœ€ä¸»è¦çš„æ˜¯ç»è¿‡ProtostuffåŒ…è£…ä¹‹åï¼Œè¿™ä¸ªSerializerå’ŒDeserializerå¯ä»¥å‘å‰å…¼å®¹ï¼ˆæ–°åŠ å­—æ®µé‡‡ç”¨é»˜è®¤å€¼ï¼‰å’Œå‘åå…¼å®¹ï¼ˆå¿½ç•¥æ–°åŠ å­—æ®µï¼‰ï¼Œè¿™ä¸ªç‰¹æ€§Avroå’ŒProtobufä¹Ÿéƒ½å…·å¤‡ã€‚

è‡ªå®šä¹‰çš„ç±»å‹æœ‰ä¸€ä¸ªä¸å¾—ä¸é¢å¯¹çš„é—®é¢˜å°±æ˜¯Kafka Producerå’ŒKafka Consumerä¹‹é—´çš„åºåˆ—åŒ–å’Œååºåˆ—åŒ–çš„å…¼å®¹æ€§ï¼Œè¯•æƒ³å¯¹äºStringSerializeræ¥è¯´ï¼ŒKafka Consumerå¯ä»¥é¡ºå…¶è‡ªç„¶çš„é‡‡ç”¨StringDeserializerï¼Œä¸è¿‡å¯¹äºCompanyè¿™ç§ä¸“ç”¨ç±»å‹ï¼ŒæŸä¸ªæœåŠ¡ä½¿ç”¨DemoSerializerè¿›è¡Œäº†åºåˆ—åŒ–ä¹‹åï¼Œé‚£ä¹ˆä¸‹æ¸¸çš„æ¶ˆè´¹è€…æœåŠ¡å¿…é¡»ä¹Ÿè¦å®ç°å¯¹åº”çš„DemoDeserializerã€‚å†è€…ï¼Œå¦‚æœä¸Šæ¸¸çš„Companyç±»å‹æ”¹å˜ï¼Œä¸‹æ¸¸ä¹Ÿéœ€è¦è·Ÿç€é‡æ–°å®ç°ä¸€ä¸ªæ–°çš„DemoSerializerï¼Œè¿™ä¸ªåé¢æ‰€é¢ä¸´çš„éš¾é¢˜å¯æƒ³è€ŒçŸ¥ã€‚æ‰€ä»¥ï¼Œå¦‚æ— ç‰¹æ®Šéœ€è¦ï¼Œç¬”è€…ä¸å»ºè®®ä½¿ç”¨è‡ªå®šä¹‰çš„åºåˆ—åŒ–å’Œååºåˆ—åŒ–å™¨ï¼›å¦‚æœ‰ä¸šåŠ¡éœ€è¦ï¼Œä¹Ÿè¦ä½¿ç”¨é€šç”¨çš„Avroã€Protobufã€Protostuffç­‰åºåˆ—åŒ–å·¥å…·åŒ…è£…ï¼Œå°½å¯èƒ½çš„å®ç°å¾—æ›´åŠ é€šç”¨ä¸”å‘å‰åå…¼å®¹ã€‚

é¢˜å¤–è¯ï¼Œå¯¹äºKafkaçš„â€œæ·±è€•è€…â€Confluentæ¥è¯´ï¼Œè¿˜æœ‰å…¶è‡ªèº«çš„ä¸€å¥—åºåˆ—åŒ–å’Œååºåˆ—åŒ–è§£å†³æ–¹æ¡ˆï¼ˆio.confluent.kafka.serializer.KafkaAvroSerializerï¼‰ï¼ŒGitHubä¸Šæœ‰ç›¸å…³èµ„æ–™ï¼Œè¯»è€…å¦‚æœ‰å…´è¶£å¯ä»¥è‡ªè¡Œæ‰©å±•å­¦ä¹ ã€‚

# 666. å½©è›‹

å¦‚æœä½ å¯¹ Kafka å¹¶å‘æ„Ÿå…´è¶£ï¼Œæ¬¢è¿åŠ å…¥æˆ‘çš„çŸ¥è¯†ä¸€èµ·äº¤æµã€‚

![çŸ¥è¯†æ˜Ÿçƒ](http://www.iocoder.cn/images/Architecture/2017_12_29/01.png)